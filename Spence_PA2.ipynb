{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34c1c1c0-6179-4040-a18a-5561c34719fa",
   "metadata": {
    "id": "34c1c1c0-6179-4040-a18a-5561c34719fa"
   },
   "source": [
    "# Sarah Spence -PA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5859b59f-9838-47c6-8434-22ee834573fd",
   "metadata": {
    "id": "5859b59f-9838-47c6-8434-22ee834573fd"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import data science algorithms and helpers \n",
    "import common_helpers as common\n",
    "from data_processing import FDR_feature_ranking as FDR\n",
    "from data_processing import normalization_and_standardization as norm\n",
    "from machine_learning import bayes_classifier as bayes\n",
    "from machine_learning import bayes_classifier_model as bayes_model\n",
    "from machine_learning import expectation_maximization as EM\n",
    "from machine_learning import parzen_window as parzen\n",
    "from machine_learning import k_fold_validation as k_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "793a4cfa-7c22-4d34-9210-da38ea5667ea",
   "metadata": {
    "id": "793a4cfa-7c22-4d34-9210-da38ea5667ea"
   },
   "outputs": [],
   "source": [
    "generated_num_features = pd.read_csv(\"data_files/trainFeatures42k.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09969228-4603-4993-9e76-3a0891c4c252",
   "metadata": {
    "id": "09969228-4603-4993-9e76-3a0891c4c252"
   },
   "source": [
    "## Problem 1 - Computational Statistics \n",
    "30 Points Total\n",
    "\n",
    "### 1. (15 points) Develop and implement the Expectation Maximization method for a generic number of clusters, features and observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201cfd82-916a-499d-838f-f34e37ff5b04",
   "metadata": {
    "id": "201cfd82-916a-499d-838f-f34e37ff5b04"
   },
   "source": [
    "Pseudo-code:\n",
    "\n",
    "def SIMPLE_EXPECTATION_MAXIMIZATION(x, k, prob, m, std, threshold):\n",
    "\n",
    "    cols <- num cols in x\n",
    "    rows <- num rows in x\n",
    "\n",
    "    itializeRows <- create a matrix of ones of size (rows, 1)\n",
    "    initializeCols <- create a matrix of ones of size (1, cols)\n",
    "\n",
    "    iterations <- 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "        prev_mean <- make a copy of m\n",
    "        prev_std <- make a copy of std\n",
    "        prev_prob <- make a copy of prob\n",
    "\n",
    "        g <- empty array\n",
    "        progKg <- empty array\n",
    "\n",
    "        # Expectation step\n",
    "        for i in range 0:k:\n",
    "            val <- get the ith column of the mean matrix and transpose \n",
    "            calc_1 <- multiply val by a matrix of ones of size (1, cols)\n",
    "            calc_2 <- subtract calc_1 from x\n",
    "            calc_3 <- square all elements in calc 2\n",
    "            calc_4 <- run calculcation np.exp(np.divide(np.divide(-1 * np.sum(calc_3, axis = 0), np.power(std[i], 2)), 2))\n",
    "            calc_5 <- perform calculation np.power(math.sqrt(2 * math.pi)* std[cluster], rows)\n",
    "            calc_e_step <- divide clac_4 by calc_5\n",
    "            g <- append calc_e_step to g\n",
    "            probKg <- append prob[:, i] * g[i] to probKg\n",
    "\n",
    "        g <- convert g to numpy array\n",
    "        probKg <- convert probKg to numpy array\n",
    "\n",
    "        calc <- take the sum of all rows of probKg\n",
    "        prob_ikn <- divide probKg by the product of reshaped_calc and a k X 1 matrix of ones\n",
    "\n",
    "        # Maximization Step\n",
    "\n",
    "        sum_prob_ikn <- sum of all cols in prob_ikn\n",
    "        for i in range 0:k:\n",
    "            calc_1 <- matrix multiplication on initializeRows and prob_ikn[i, :]\n",
    "            calc_2 <- multiply calc_1 and x\n",
    "            calc_3 <- divide calc_2 by sum_prob_ikn[i]\n",
    "            m[:, i] <- the sum of all cols in calc 3\n",
    "\n",
    "            calc_1 <- multiply m[:, i] by initializeCols\n",
    "            calc_2 <- square all elements in x - calc_2 \n",
    "            calc_3 <- multiply calc_2 and prob_ikn[i, :] then take the sum across all rows\n",
    "            calc_4 <- divide calc_3 by sum_prob_ikn[i]\n",
    "            calc_5 <- divide calc_4 by rows\n",
    "            std[i] <- take the square root of calc_5\n",
    "        \n",
    "        prob <- divide sum_prob_ikn by the sum of sum_prob_ikn\n",
    "        \n",
    "        # Determine convergence\n",
    "        mean_delta = max(np.sqrt(np.sum(np.power(m - prev_mean, 2), axis=0)))\n",
    "        s_mean = np.mean(np.sqrt(np.sum(np.power(m, 2), axis=0)))\n",
    "        conv_mean = mean_delta <= (s_mean * threshold)\n",
    "\n",
    "        std_delta = math.sqrt(np.sum(np.power(std - prev_std, 2), axis=0))\n",
    "        s_std = np.mean(np.sqrt(np.sum(np.power(std, 2))))\n",
    "        conv_std = std_delta <= (s_std * threshold)\n",
    "\n",
    "        prob_delta = max(np.sqrt(np.sum(np.power(prob - prev_prob, 2), axis=0)))\n",
    "        s_prob = np.mean(math.sqrt(np.sum(np.power(prob, 2))))\n",
    "        conv_prob = prob_delta <= (s_prob * threshold)\n",
    "\n",
    "\n",
    "        # If the mean, std, and probabiity have converged, break\n",
    "        if conv_mean and conv_std  and conv_prob:\n",
    "            break\n",
    "\n",
    "    return prob, m, std, prob_ikn, iterations\n",
    "\n",
    "#### See the code for this algorithm in the machine_learning/expectation_maximization.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qBROyFIYY6Oy",
   "metadata": {
    "id": "qBROyFIYY6Oy"
   },
   "source": [
    "### 2. (15 points total) Apply your implementation using the features generated from HW 2. \n",
    "Identify and use the top two ranked features to separate three numerical values, e.g., 0, 1, 4. This will require that k = 3. Use 100 observations for each of the three numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "32471ee5-0eb8-4e03-85cd-90f24435e488",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "32471ee5-0eb8-4e03-85cd-90f24435e488",
    "outputId": "b6a8c821-ae65-46c3-8f09-8aef5eda7fbb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_c53b3\">\n",
       "  <caption>FDR Feature Ranking Multiclass (One vs. Rest)</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c53b3_level0_col0\" class=\"col_heading level0 col0\" >class combinations</th>\n",
       "      <th id=\"T_c53b3_level0_col1\" class=\"col_heading level0 col1\" >0</th>\n",
       "      <th id=\"T_c53b3_level0_col2\" class=\"col_heading level0 col2\" >1</th>\n",
       "      <th id=\"T_c53b3_level0_col3\" class=\"col_heading level0 col3\" >2</th>\n",
       "      <th id=\"T_c53b3_level0_col4\" class=\"col_heading level0 col4\" >3</th>\n",
       "      <th id=\"T_c53b3_level0_col5\" class=\"col_heading level0 col5\" >4</th>\n",
       "      <th id=\"T_c53b3_level0_col6\" class=\"col_heading level0 col6\" >5</th>\n",
       "      <th id=\"T_c53b3_level0_col7\" class=\"col_heading level0 col7\" >6</th>\n",
       "      <th id=\"T_c53b3_level0_col8\" class=\"col_heading level0 col8\" >7</th>\n",
       "      <th id=\"T_c53b3_level0_col9\" class=\"col_heading level0 col9\" >8</th>\n",
       "      <th id=\"T_c53b3_level0_col10\" class=\"col_heading level0 col10\" >9</th>\n",
       "      <th id=\"T_c53b3_level0_col11\" class=\"col_heading level0 col11\" >10</th>\n",
       "      <th id=\"T_c53b3_level0_col12\" class=\"col_heading level0 col12\" >11</th>\n",
       "      <th id=\"T_c53b3_level0_col13\" class=\"col_heading level0 col13\" >12</th>\n",
       "      <th id=\"T_c53b3_level0_col14\" class=\"col_heading level0 col14\" >13</th>\n",
       "      <th id=\"T_c53b3_level0_col15\" class=\"col_heading level0 col15\" >14</th>\n",
       "      <th id=\"T_c53b3_level0_col16\" class=\"col_heading level0 col16\" >15</th>\n",
       "      <th id=\"T_c53b3_level0_col17\" class=\"col_heading level0 col17\" >16</th>\n",
       "      <th id=\"T_c53b3_level0_col18\" class=\"col_heading level0 col18\" >17</th>\n",
       "      <th id=\"T_c53b3_level0_col19\" class=\"col_heading level0 col19\" >18</th>\n",
       "      <th id=\"T_c53b3_level0_col20\" class=\"col_heading level0 col20\" >19</th>\n",
       "      <th id=\"T_c53b3_level0_col21\" class=\"col_heading level0 col21\" >20</th>\n",
       "      <th id=\"T_c53b3_level0_col22\" class=\"col_heading level0 col22\" >21</th>\n",
       "      <th id=\"T_c53b3_level0_col23\" class=\"col_heading level0 col23\" >22</th>\n",
       "      <th id=\"T_c53b3_level0_col24\" class=\"col_heading level0 col24\" >23</th>\n",
       "      <th id=\"T_c53b3_level0_col25\" class=\"col_heading level0 col25\" >24</th>\n",
       "      <th id=\"T_c53b3_level0_col26\" class=\"col_heading level0 col26\" >25</th>\n",
       "      <th id=\"T_c53b3_level0_col27\" class=\"col_heading level0 col27\" >26</th>\n",
       "      <th id=\"T_c53b3_level0_col28\" class=\"col_heading level0 col28\" >27</th>\n",
       "      <th id=\"T_c53b3_level0_col29\" class=\"col_heading level0 col29\" >28</th>\n",
       "      <th id=\"T_c53b3_level0_col30\" class=\"col_heading level0 col30\" >29</th>\n",
       "      <th id=\"T_c53b3_level0_col31\" class=\"col_heading level0 col31\" >30</th>\n",
       "      <th id=\"T_c53b3_level0_col32\" class=\"col_heading level0 col32\" >31</th>\n",
       "      <th id=\"T_c53b3_level0_col33\" class=\"col_heading level0 col33\" >32</th>\n",
       "      <th id=\"T_c53b3_level0_col34\" class=\"col_heading level0 col34\" >33</th>\n",
       "      <th id=\"T_c53b3_level0_col35\" class=\"col_heading level0 col35\" >34</th>\n",
       "      <th id=\"T_c53b3_level0_col36\" class=\"col_heading level0 col36\" >35</th>\n",
       "      <th id=\"T_c53b3_level0_col37\" class=\"col_heading level0 col37\" >36</th>\n",
       "      <th id=\"T_c53b3_level0_col38\" class=\"col_heading level0 col38\" >37</th>\n",
       "      <th id=\"T_c53b3_level0_col39\" class=\"col_heading level0 col39\" >38</th>\n",
       "      <th id=\"T_c53b3_level0_col40\" class=\"col_heading level0 col40\" >39</th>\n",
       "      <th id=\"T_c53b3_level0_col41\" class=\"col_heading level0 col41\" >40</th>\n",
       "      <th id=\"T_c53b3_level0_col42\" class=\"col_heading level0 col42\" >41</th>\n",
       "      <th id=\"T_c53b3_level0_col43\" class=\"col_heading level0 col43\" >42</th>\n",
       "      <th id=\"T_c53b3_level0_col44\" class=\"col_heading level0 col44\" >43</th>\n",
       "      <th id=\"T_c53b3_level0_col45\" class=\"col_heading level0 col45\" >44</th>\n",
       "      <th id=\"T_c53b3_level0_col46\" class=\"col_heading level0 col46\" >45</th>\n",
       "      <th id=\"T_c53b3_level0_col47\" class=\"col_heading level0 col47\" >46</th>\n",
       "      <th id=\"T_c53b3_level0_col48\" class=\"col_heading level0 col48\" >47</th>\n",
       "      <th id=\"T_c53b3_level0_col49\" class=\"col_heading level0 col49\" >48</th>\n",
       "      <th id=\"T_c53b3_level0_col50\" class=\"col_heading level0 col50\" >49</th>\n",
       "      <th id=\"T_c53b3_level0_col51\" class=\"col_heading level0 col51\" >50</th>\n",
       "      <th id=\"T_c53b3_level0_col52\" class=\"col_heading level0 col52\" >51</th>\n",
       "      <th id=\"T_c53b3_level0_col53\" class=\"col_heading level0 col53\" >52</th>\n",
       "      <th id=\"T_c53b3_level0_col54\" class=\"col_heading level0 col54\" >53</th>\n",
       "      <th id=\"T_c53b3_level0_col55\" class=\"col_heading level0 col55\" >54</th>\n",
       "      <th id=\"T_c53b3_level0_col56\" class=\"col_heading level0 col56\" >55</th>\n",
       "      <th id=\"T_c53b3_level0_col57\" class=\"col_heading level0 col57\" >56</th>\n",
       "      <th id=\"T_c53b3_level0_col58\" class=\"col_heading level0 col58\" >57</th>\n",
       "      <th id=\"T_c53b3_level0_col59\" class=\"col_heading level0 col59\" >58</th>\n",
       "      <th id=\"T_c53b3_level0_col60\" class=\"col_heading level0 col60\" >59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c53b3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c53b3_row0_col0\" class=\"data row0 col0\" >0 vs. rest</td>\n",
       "      <td id=\"T_c53b3_row0_col1\" class=\"data row0 col1\" >1.325256</td>\n",
       "      <td id=\"T_c53b3_row0_col2\" class=\"data row0 col2\" >0.255820</td>\n",
       "      <td id=\"T_c53b3_row0_col3\" class=\"data row0 col3\" >0.128279</td>\n",
       "      <td id=\"T_c53b3_row0_col4\" class=\"data row0 col4\" >0.002017</td>\n",
       "      <td id=\"T_c53b3_row0_col5\" class=\"data row0 col5\" >0.970632</td>\n",
       "      <td id=\"T_c53b3_row0_col6\" class=\"data row0 col6\" >0.004775</td>\n",
       "      <td id=\"T_c53b3_row0_col7\" class=\"data row0 col7\" >0.234047</td>\n",
       "      <td id=\"T_c53b3_row0_col8\" class=\"data row0 col8\" >0.004373</td>\n",
       "      <td id=\"T_c53b3_row0_col9\" class=\"data row0 col9\" >0.008919</td>\n",
       "      <td id=\"T_c53b3_row0_col10\" class=\"data row0 col10\" >0.058024</td>\n",
       "      <td id=\"T_c53b3_row0_col11\" class=\"data row0 col11\" >0.038586</td>\n",
       "      <td id=\"T_c53b3_row0_col12\" class=\"data row0 col12\" >0.000696</td>\n",
       "      <td id=\"T_c53b3_row0_col13\" class=\"data row0 col13\" >0.038735</td>\n",
       "      <td id=\"T_c53b3_row0_col14\" class=\"data row0 col14\" >0.010703</td>\n",
       "      <td id=\"T_c53b3_row0_col15\" class=\"data row0 col15\" >0.006912</td>\n",
       "      <td id=\"T_c53b3_row0_col16\" class=\"data row0 col16\" >0.003460</td>\n",
       "      <td id=\"T_c53b3_row0_col17\" class=\"data row0 col17\" >0.006619</td>\n",
       "      <td id=\"T_c53b3_row0_col18\" class=\"data row0 col18\" >0.002539</td>\n",
       "      <td id=\"T_c53b3_row0_col19\" class=\"data row0 col19\" >0.008286</td>\n",
       "      <td id=\"T_c53b3_row0_col20\" class=\"data row0 col20\" >0.031836</td>\n",
       "      <td id=\"T_c53b3_row0_col21\" class=\"data row0 col21\" >2.353779</td>\n",
       "      <td id=\"T_c53b3_row0_col22\" class=\"data row0 col22\" >0.506806</td>\n",
       "      <td id=\"T_c53b3_row0_col23\" class=\"data row0 col23\" >0.128745</td>\n",
       "      <td id=\"T_c53b3_row0_col24\" class=\"data row0 col24\" >0.166735</td>\n",
       "      <td id=\"T_c53b3_row0_col25\" class=\"data row0 col25\" >0.004132</td>\n",
       "      <td id=\"T_c53b3_row0_col26\" class=\"data row0 col26\" >0.000431</td>\n",
       "      <td id=\"T_c53b3_row0_col27\" class=\"data row0 col27\" >0.131638</td>\n",
       "      <td id=\"T_c53b3_row0_col28\" class=\"data row0 col28\" >0.075195</td>\n",
       "      <td id=\"T_c53b3_row0_col29\" class=\"data row0 col29\" >0.023656</td>\n",
       "      <td id=\"T_c53b3_row0_col30\" class=\"data row0 col30\" >0.064356</td>\n",
       "      <td id=\"T_c53b3_row0_col31\" class=\"data row0 col31\" >0.024790</td>\n",
       "      <td id=\"T_c53b3_row0_col32\" class=\"data row0 col32\" >0.024631</td>\n",
       "      <td id=\"T_c53b3_row0_col33\" class=\"data row0 col33\" >0.006895</td>\n",
       "      <td id=\"T_c53b3_row0_col34\" class=\"data row0 col34\" >0.070535</td>\n",
       "      <td id=\"T_c53b3_row0_col35\" class=\"data row0 col35\" >0.000662</td>\n",
       "      <td id=\"T_c53b3_row0_col36\" class=\"data row0 col36\" >0.023829</td>\n",
       "      <td id=\"T_c53b3_row0_col37\" class=\"data row0 col37\" >0.000359</td>\n",
       "      <td id=\"T_c53b3_row0_col38\" class=\"data row0 col38\" >0.009664</td>\n",
       "      <td id=\"T_c53b3_row0_col39\" class=\"data row0 col39\" >0.004764</td>\n",
       "      <td id=\"T_c53b3_row0_col40\" class=\"data row0 col40\" >0.083516</td>\n",
       "      <td id=\"T_c53b3_row0_col41\" class=\"data row0 col41\" >0.462854</td>\n",
       "      <td id=\"T_c53b3_row0_col42\" class=\"data row0 col42\" >0.000274</td>\n",
       "      <td id=\"T_c53b3_row0_col43\" class=\"data row0 col43\" >1.226648</td>\n",
       "      <td id=\"T_c53b3_row0_col44\" class=\"data row0 col44\" >0.086013</td>\n",
       "      <td id=\"T_c53b3_row0_col45\" class=\"data row0 col45\" >0.044070</td>\n",
       "      <td id=\"T_c53b3_row0_col46\" class=\"data row0 col46\" >0.048264</td>\n",
       "      <td id=\"T_c53b3_row0_col47\" class=\"data row0 col47\" >0.251432</td>\n",
       "      <td id=\"T_c53b3_row0_col48\" class=\"data row0 col48\" >0.001831</td>\n",
       "      <td id=\"T_c53b3_row0_col49\" class=\"data row0 col49\" >0.042225</td>\n",
       "      <td id=\"T_c53b3_row0_col50\" class=\"data row0 col50\" >0.015487</td>\n",
       "      <td id=\"T_c53b3_row0_col51\" class=\"data row0 col51\" >0.008370</td>\n",
       "      <td id=\"T_c53b3_row0_col52\" class=\"data row0 col52\" >0.009667</td>\n",
       "      <td id=\"T_c53b3_row0_col53\" class=\"data row0 col53\" >0.028293</td>\n",
       "      <td id=\"T_c53b3_row0_col54\" class=\"data row0 col54\" >0.030895</td>\n",
       "      <td id=\"T_c53b3_row0_col55\" class=\"data row0 col55\" >0.021684</td>\n",
       "      <td id=\"T_c53b3_row0_col56\" class=\"data row0 col56\" >0.019457</td>\n",
       "      <td id=\"T_c53b3_row0_col57\" class=\"data row0 col57\" >0.000509</td>\n",
       "      <td id=\"T_c53b3_row0_col58\" class=\"data row0 col58\" >0.013225</td>\n",
       "      <td id=\"T_c53b3_row0_col59\" class=\"data row0 col59\" >0.031244</td>\n",
       "      <td id=\"T_c53b3_row0_col60\" class=\"data row0 col60\" >0.005341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c53b3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c53b3_row1_col0\" class=\"data row1 col0\" >1 vs. rest</td>\n",
       "      <td id=\"T_c53b3_row1_col1\" class=\"data row1 col1\" >0.129503</td>\n",
       "      <td id=\"T_c53b3_row1_col2\" class=\"data row1 col2\" >0.060734</td>\n",
       "      <td id=\"T_c53b3_row1_col3\" class=\"data row1 col3\" >0.129896</td>\n",
       "      <td id=\"T_c53b3_row1_col4\" class=\"data row1 col4\" >0.021977</td>\n",
       "      <td id=\"T_c53b3_row1_col5\" class=\"data row1 col5\" >0.005897</td>\n",
       "      <td id=\"T_c53b3_row1_col6\" class=\"data row1 col6\" >0.019788</td>\n",
       "      <td id=\"T_c53b3_row1_col7\" class=\"data row1 col7\" >0.153930</td>\n",
       "      <td id=\"T_c53b3_row1_col8\" class=\"data row1 col8\" >0.012081</td>\n",
       "      <td id=\"T_c53b3_row1_col9\" class=\"data row1 col9\" >0.000547</td>\n",
       "      <td id=\"T_c53b3_row1_col10\" class=\"data row1 col10\" >0.000435</td>\n",
       "      <td id=\"T_c53b3_row1_col11\" class=\"data row1 col11\" >0.116606</td>\n",
       "      <td id=\"T_c53b3_row1_col12\" class=\"data row1 col12\" >0.114315</td>\n",
       "      <td id=\"T_c53b3_row1_col13\" class=\"data row1 col13\" >0.164304</td>\n",
       "      <td id=\"T_c53b3_row1_col14\" class=\"data row1 col14\" >0.006533</td>\n",
       "      <td id=\"T_c53b3_row1_col15\" class=\"data row1 col15\" >0.005780</td>\n",
       "      <td id=\"T_c53b3_row1_col16\" class=\"data row1 col16\" >0.068386</td>\n",
       "      <td id=\"T_c53b3_row1_col17\" class=\"data row1 col17\" >0.015697</td>\n",
       "      <td id=\"T_c53b3_row1_col18\" class=\"data row1 col18\" >0.028051</td>\n",
       "      <td id=\"T_c53b3_row1_col19\" class=\"data row1 col19\" >0.042117</td>\n",
       "      <td id=\"T_c53b3_row1_col20\" class=\"data row1 col20\" >0.000810</td>\n",
       "      <td id=\"T_c53b3_row1_col21\" class=\"data row1 col21\" >3.081181</td>\n",
       "      <td id=\"T_c53b3_row1_col22\" class=\"data row1 col22\" >0.996539</td>\n",
       "      <td id=\"T_c53b3_row1_col23\" class=\"data row1 col23\" >0.050958</td>\n",
       "      <td id=\"T_c53b3_row1_col24\" class=\"data row1 col24\" >0.074599</td>\n",
       "      <td id=\"T_c53b3_row1_col25\" class=\"data row1 col25\" >0.024863</td>\n",
       "      <td id=\"T_c53b3_row1_col26\" class=\"data row1 col26\" >0.000018</td>\n",
       "      <td id=\"T_c53b3_row1_col27\" class=\"data row1 col27\" >0.005877</td>\n",
       "      <td id=\"T_c53b3_row1_col28\" class=\"data row1 col28\" >0.006931</td>\n",
       "      <td id=\"T_c53b3_row1_col29\" class=\"data row1 col29\" >0.223421</td>\n",
       "      <td id=\"T_c53b3_row1_col30\" class=\"data row1 col30\" >0.002294</td>\n",
       "      <td id=\"T_c53b3_row1_col31\" class=\"data row1 col31\" >0.295796</td>\n",
       "      <td id=\"T_c53b3_row1_col32\" class=\"data row1 col32\" >0.180545</td>\n",
       "      <td id=\"T_c53b3_row1_col33\" class=\"data row1 col33\" >0.081783</td>\n",
       "      <td id=\"T_c53b3_row1_col34\" class=\"data row1 col34\" >0.000015</td>\n",
       "      <td id=\"T_c53b3_row1_col35\" class=\"data row1 col35\" >0.014543</td>\n",
       "      <td id=\"T_c53b3_row1_col36\" class=\"data row1 col36\" >0.009074</td>\n",
       "      <td id=\"T_c53b3_row1_col37\" class=\"data row1 col37\" >0.010710</td>\n",
       "      <td id=\"T_c53b3_row1_col38\" class=\"data row1 col38\" >0.017408</td>\n",
       "      <td id=\"T_c53b3_row1_col39\" class=\"data row1 col39\" >0.013598</td>\n",
       "      <td id=\"T_c53b3_row1_col40\" class=\"data row1 col40\" >0.007049</td>\n",
       "      <td id=\"T_c53b3_row1_col41\" class=\"data row1 col41\" >0.015896</td>\n",
       "      <td id=\"T_c53b3_row1_col42\" class=\"data row1 col42\" >0.008289</td>\n",
       "      <td id=\"T_c53b3_row1_col43\" class=\"data row1 col43\" >0.038248</td>\n",
       "      <td id=\"T_c53b3_row1_col44\" class=\"data row1 col44\" >0.338424</td>\n",
       "      <td id=\"T_c53b3_row1_col45\" class=\"data row1 col45\" >0.321322</td>\n",
       "      <td id=\"T_c53b3_row1_col46\" class=\"data row1 col46\" >0.593496</td>\n",
       "      <td id=\"T_c53b3_row1_col47\" class=\"data row1 col47\" >0.063258</td>\n",
       "      <td id=\"T_c53b3_row1_col48\" class=\"data row1 col48\" >0.002649</td>\n",
       "      <td id=\"T_c53b3_row1_col49\" class=\"data row1 col49\" >0.041663</td>\n",
       "      <td id=\"T_c53b3_row1_col50\" class=\"data row1 col50\" >0.029045</td>\n",
       "      <td id=\"T_c53b3_row1_col51\" class=\"data row1 col51\" >0.006240</td>\n",
       "      <td id=\"T_c53b3_row1_col52\" class=\"data row1 col52\" >0.076545</td>\n",
       "      <td id=\"T_c53b3_row1_col53\" class=\"data row1 col53\" >0.053101</td>\n",
       "      <td id=\"T_c53b3_row1_col54\" class=\"data row1 col54\" >0.012006</td>\n",
       "      <td id=\"T_c53b3_row1_col55\" class=\"data row1 col55\" >0.001030</td>\n",
       "      <td id=\"T_c53b3_row1_col56\" class=\"data row1 col56\" >0.011069</td>\n",
       "      <td id=\"T_c53b3_row1_col57\" class=\"data row1 col57\" >0.000868</td>\n",
       "      <td id=\"T_c53b3_row1_col58\" class=\"data row1 col58\" >0.044990</td>\n",
       "      <td id=\"T_c53b3_row1_col59\" class=\"data row1 col59\" >0.026074</td>\n",
       "      <td id=\"T_c53b3_row1_col60\" class=\"data row1 col60\" >0.007561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c53b3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c53b3_row2_col0\" class=\"data row2 col0\" >4 vs. rest</td>\n",
       "      <td id=\"T_c53b3_row2_col1\" class=\"data row2 col1\" >0.096326</td>\n",
       "      <td id=\"T_c53b3_row2_col2\" class=\"data row2 col2\" >0.025827</td>\n",
       "      <td id=\"T_c53b3_row2_col3\" class=\"data row2 col3\" >0.317742</td>\n",
       "      <td id=\"T_c53b3_row2_col4\" class=\"data row2 col4\" >0.027625</td>\n",
       "      <td id=\"T_c53b3_row2_col5\" class=\"data row2 col5\" >0.510723</td>\n",
       "      <td id=\"T_c53b3_row2_col6\" class=\"data row2 col6\" >0.014681</td>\n",
       "      <td id=\"T_c53b3_row2_col7\" class=\"data row2 col7\" >0.036768</td>\n",
       "      <td id=\"T_c53b3_row2_col8\" class=\"data row2 col8\" >0.184603</td>\n",
       "      <td id=\"T_c53b3_row2_col9\" class=\"data row2 col9\" >0.007633</td>\n",
       "      <td id=\"T_c53b3_row2_col10\" class=\"data row2 col10\" >0.022759</td>\n",
       "      <td id=\"T_c53b3_row2_col11\" class=\"data row2 col11\" >0.013400</td>\n",
       "      <td id=\"T_c53b3_row2_col12\" class=\"data row2 col12\" >0.081295</td>\n",
       "      <td id=\"T_c53b3_row2_col13\" class=\"data row2 col13\" >0.048384</td>\n",
       "      <td id=\"T_c53b3_row2_col14\" class=\"data row2 col14\" >0.000030</td>\n",
       "      <td id=\"T_c53b3_row2_col15\" class=\"data row2 col15\" >0.008328</td>\n",
       "      <td id=\"T_c53b3_row2_col16\" class=\"data row2 col16\" >0.043175</td>\n",
       "      <td id=\"T_c53b3_row2_col17\" class=\"data row2 col17\" >0.014010</td>\n",
       "      <td id=\"T_c53b3_row2_col18\" class=\"data row2 col18\" >0.000884</td>\n",
       "      <td id=\"T_c53b3_row2_col19\" class=\"data row2 col19\" >0.007851</td>\n",
       "      <td id=\"T_c53b3_row2_col20\" class=\"data row2 col20\" >0.090728</td>\n",
       "      <td id=\"T_c53b3_row2_col21\" class=\"data row2 col21\" >0.199545</td>\n",
       "      <td id=\"T_c53b3_row2_col22\" class=\"data row2 col22\" >0.190943</td>\n",
       "      <td id=\"T_c53b3_row2_col23\" class=\"data row2 col23\" >0.251274</td>\n",
       "      <td id=\"T_c53b3_row2_col24\" class=\"data row2 col24\" >0.014661</td>\n",
       "      <td id=\"T_c53b3_row2_col25\" class=\"data row2 col25\" >0.033112</td>\n",
       "      <td id=\"T_c53b3_row2_col26\" class=\"data row2 col26\" >0.007958</td>\n",
       "      <td id=\"T_c53b3_row2_col27\" class=\"data row2 col27\" >0.002044</td>\n",
       "      <td id=\"T_c53b3_row2_col28\" class=\"data row2 col28\" >0.233451</td>\n",
       "      <td id=\"T_c53b3_row2_col29\" class=\"data row2 col29\" >0.023214</td>\n",
       "      <td id=\"T_c53b3_row2_col30\" class=\"data row2 col30\" >0.035490</td>\n",
       "      <td id=\"T_c53b3_row2_col31\" class=\"data row2 col31\" >0.001012</td>\n",
       "      <td id=\"T_c53b3_row2_col32\" class=\"data row2 col32\" >0.000067</td>\n",
       "      <td id=\"T_c53b3_row2_col33\" class=\"data row2 col33\" >0.001546</td>\n",
       "      <td id=\"T_c53b3_row2_col34\" class=\"data row2 col34\" >0.005116</td>\n",
       "      <td id=\"T_c53b3_row2_col35\" class=\"data row2 col35\" >0.061902</td>\n",
       "      <td id=\"T_c53b3_row2_col36\" class=\"data row2 col36\" >0.003123</td>\n",
       "      <td id=\"T_c53b3_row2_col37\" class=\"data row2 col37\" >0.026989</td>\n",
       "      <td id=\"T_c53b3_row2_col38\" class=\"data row2 col38\" >0.000925</td>\n",
       "      <td id=\"T_c53b3_row2_col39\" class=\"data row2 col39\" >0.000258</td>\n",
       "      <td id=\"T_c53b3_row2_col40\" class=\"data row2 col40\" >0.024298</td>\n",
       "      <td id=\"T_c53b3_row2_col41\" class=\"data row2 col41\" >1.039454</td>\n",
       "      <td id=\"T_c53b3_row2_col42\" class=\"data row2 col42\" >0.000904</td>\n",
       "      <td id=\"T_c53b3_row2_col43\" class=\"data row2 col43\" >0.891979</td>\n",
       "      <td id=\"T_c53b3_row2_col44\" class=\"data row2 col44\" >0.025128</td>\n",
       "      <td id=\"T_c53b3_row2_col45\" class=\"data row2 col45\" >0.257124</td>\n",
       "      <td id=\"T_c53b3_row2_col46\" class=\"data row2 col46\" >0.000059</td>\n",
       "      <td id=\"T_c53b3_row2_col47\" class=\"data row2 col47\" >0.350181</td>\n",
       "      <td id=\"T_c53b3_row2_col48\" class=\"data row2 col48\" >0.000074</td>\n",
       "      <td id=\"T_c53b3_row2_col49\" class=\"data row2 col49\" >0.104906</td>\n",
       "      <td id=\"T_c53b3_row2_col50\" class=\"data row2 col50\" >0.025254</td>\n",
       "      <td id=\"T_c53b3_row2_col51\" class=\"data row2 col51\" >0.066792</td>\n",
       "      <td id=\"T_c53b3_row2_col52\" class=\"data row2 col52\" >0.018072</td>\n",
       "      <td id=\"T_c53b3_row2_col53\" class=\"data row2 col53\" >0.087941</td>\n",
       "      <td id=\"T_c53b3_row2_col54\" class=\"data row2 col54\" >0.000085</td>\n",
       "      <td id=\"T_c53b3_row2_col55\" class=\"data row2 col55\" >0.014994</td>\n",
       "      <td id=\"T_c53b3_row2_col56\" class=\"data row2 col56\" >0.002232</td>\n",
       "      <td id=\"T_c53b3_row2_col57\" class=\"data row2 col57\" >0.092064</td>\n",
       "      <td id=\"T_c53b3_row2_col58\" class=\"data row2 col58\" >0.014654</td>\n",
       "      <td id=\"T_c53b3_row2_col59\" class=\"data row2 col59\" >0.010690</td>\n",
       "      <td id=\"T_c53b3_row2_col60\" class=\"data row2 col60\" >0.001633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c53b3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c53b3_row3_col0\" class=\"data row3 col0\" >sum</td>\n",
       "      <td id=\"T_c53b3_row3_col1\" class=\"data row3 col1\" >1.551085</td>\n",
       "      <td id=\"T_c53b3_row3_col2\" class=\"data row3 col2\" >0.342382</td>\n",
       "      <td id=\"T_c53b3_row3_col3\" class=\"data row3 col3\" >0.575917</td>\n",
       "      <td id=\"T_c53b3_row3_col4\" class=\"data row3 col4\" >0.051618</td>\n",
       "      <td id=\"T_c53b3_row3_col5\" class=\"data row3 col5\" >1.487251</td>\n",
       "      <td id=\"T_c53b3_row3_col6\" class=\"data row3 col6\" >0.039245</td>\n",
       "      <td id=\"T_c53b3_row3_col7\" class=\"data row3 col7\" >0.424745</td>\n",
       "      <td id=\"T_c53b3_row3_col8\" class=\"data row3 col8\" >0.201057</td>\n",
       "      <td id=\"T_c53b3_row3_col9\" class=\"data row3 col9\" >0.017099</td>\n",
       "      <td id=\"T_c53b3_row3_col10\" class=\"data row3 col10\" >0.081218</td>\n",
       "      <td id=\"T_c53b3_row3_col11\" class=\"data row3 col11\" >0.168591</td>\n",
       "      <td id=\"T_c53b3_row3_col12\" class=\"data row3 col12\" >0.196305</td>\n",
       "      <td id=\"T_c53b3_row3_col13\" class=\"data row3 col13\" >0.251423</td>\n",
       "      <td id=\"T_c53b3_row3_col14\" class=\"data row3 col14\" >0.017267</td>\n",
       "      <td id=\"T_c53b3_row3_col15\" class=\"data row3 col15\" >0.021020</td>\n",
       "      <td id=\"T_c53b3_row3_col16\" class=\"data row3 col16\" >0.115021</td>\n",
       "      <td id=\"T_c53b3_row3_col17\" class=\"data row3 col17\" >0.036327</td>\n",
       "      <td id=\"T_c53b3_row3_col18\" class=\"data row3 col18\" >0.031474</td>\n",
       "      <td id=\"T_c53b3_row3_col19\" class=\"data row3 col19\" >0.058254</td>\n",
       "      <td id=\"T_c53b3_row3_col20\" class=\"data row3 col20\" >0.123373</td>\n",
       "      <td id=\"T_c53b3_row3_col21\" class=\"data row3 col21\" >5.634506</td>\n",
       "      <td id=\"T_c53b3_row3_col22\" class=\"data row3 col22\" >1.694288</td>\n",
       "      <td id=\"T_c53b3_row3_col23\" class=\"data row3 col23\" >0.430978</td>\n",
       "      <td id=\"T_c53b3_row3_col24\" class=\"data row3 col24\" >0.255995</td>\n",
       "      <td id=\"T_c53b3_row3_col25\" class=\"data row3 col25\" >0.062107</td>\n",
       "      <td id=\"T_c53b3_row3_col26\" class=\"data row3 col26\" >0.008407</td>\n",
       "      <td id=\"T_c53b3_row3_col27\" class=\"data row3 col27\" >0.139559</td>\n",
       "      <td id=\"T_c53b3_row3_col28\" class=\"data row3 col28\" >0.315577</td>\n",
       "      <td id=\"T_c53b3_row3_col29\" class=\"data row3 col29\" >0.270291</td>\n",
       "      <td id=\"T_c53b3_row3_col30\" class=\"data row3 col30\" >0.102139</td>\n",
       "      <td id=\"T_c53b3_row3_col31\" class=\"data row3 col31\" >0.321598</td>\n",
       "      <td id=\"T_c53b3_row3_col32\" class=\"data row3 col32\" >0.205243</td>\n",
       "      <td id=\"T_c53b3_row3_col33\" class=\"data row3 col33\" >0.090224</td>\n",
       "      <td id=\"T_c53b3_row3_col34\" class=\"data row3 col34\" >0.075666</td>\n",
       "      <td id=\"T_c53b3_row3_col35\" class=\"data row3 col35\" >0.077108</td>\n",
       "      <td id=\"T_c53b3_row3_col36\" class=\"data row3 col36\" >0.036027</td>\n",
       "      <td id=\"T_c53b3_row3_col37\" class=\"data row3 col37\" >0.038058</td>\n",
       "      <td id=\"T_c53b3_row3_col38\" class=\"data row3 col38\" >0.027997</td>\n",
       "      <td id=\"T_c53b3_row3_col39\" class=\"data row3 col39\" >0.018619</td>\n",
       "      <td id=\"T_c53b3_row3_col40\" class=\"data row3 col40\" >0.114863</td>\n",
       "      <td id=\"T_c53b3_row3_col41\" class=\"data row3 col41\" >1.518204</td>\n",
       "      <td id=\"T_c53b3_row3_col42\" class=\"data row3 col42\" >0.009468</td>\n",
       "      <td id=\"T_c53b3_row3_col43\" class=\"data row3 col43\" >2.156875</td>\n",
       "      <td id=\"T_c53b3_row3_col44\" class=\"data row3 col44\" >0.449566</td>\n",
       "      <td id=\"T_c53b3_row3_col45\" class=\"data row3 col45\" >0.622515</td>\n",
       "      <td id=\"T_c53b3_row3_col46\" class=\"data row3 col46\" >0.641819</td>\n",
       "      <td id=\"T_c53b3_row3_col47\" class=\"data row3 col47\" >0.664870</td>\n",
       "      <td id=\"T_c53b3_row3_col48\" class=\"data row3 col48\" >0.004554</td>\n",
       "      <td id=\"T_c53b3_row3_col49\" class=\"data row3 col49\" >0.188794</td>\n",
       "      <td id=\"T_c53b3_row3_col50\" class=\"data row3 col50\" >0.069786</td>\n",
       "      <td id=\"T_c53b3_row3_col51\" class=\"data row3 col51\" >0.081401</td>\n",
       "      <td id=\"T_c53b3_row3_col52\" class=\"data row3 col52\" >0.104284</td>\n",
       "      <td id=\"T_c53b3_row3_col53\" class=\"data row3 col53\" >0.169336</td>\n",
       "      <td id=\"T_c53b3_row3_col54\" class=\"data row3 col54\" >0.042986</td>\n",
       "      <td id=\"T_c53b3_row3_col55\" class=\"data row3 col55\" >0.037708</td>\n",
       "      <td id=\"T_c53b3_row3_col56\" class=\"data row3 col56\" >0.032758</td>\n",
       "      <td id=\"T_c53b3_row3_col57\" class=\"data row3 col57\" >0.093441</td>\n",
       "      <td id=\"T_c53b3_row3_col58\" class=\"data row3 col58\" >0.072868</td>\n",
       "      <td id=\"T_c53b3_row3_col59\" class=\"data row3 col59\" >0.068009</td>\n",
       "      <td id=\"T_c53b3_row3_col60\" class=\"data row3 col60\" >0.014536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x299fdb820>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename data columns to be indexed by 0\n",
    "columns = [\"label\"] + [i for i in range(60)]\n",
    "generated_num_features = generated_num_features.set_axis(columns, axis=1)\n",
    "\n",
    "labels = [i for i in range(10)]\n",
    "\n",
    "# Generate the FDR table to rank features by class combinations for classes 0, 1, and 4\n",
    "FDR_table, _, rankings = FDR.FDR_multiclass_feature_ranking(generated_num_features, [0, 1, 4], \"label\", \"sum\")\n",
    "FDR_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3b1b9dd0-a951-4776-87ef-47f6167567d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3b1b9dd0-a951-4776-87ef-47f6167567d4",
    "outputId": "ad3c1bfb-a789-4986-b77c-970cca823138"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top two features to separate classes 0, 1, and 4 are [20, 42]\n"
     ]
    }
   ],
   "source": [
    "print(f\"The top two features to separate classes 0, 1, and 4 are {rankings[:2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "df7d289d-9dd6-46d9-8df7-4ed52b462fd3",
   "metadata": {
    "id": "df7d289d-9dd6-46d9-8df7-4ed52b462fd3"
   },
   "outputs": [],
   "source": [
    "# Get the top two features from the dataframe\n",
    "top_features_df = generated_num_features.filter([\"label\"] + rankings[:2], axis=1)\n",
    "\n",
    "# Get 100 class examples of classes [0, 1, 4]\n",
    "number_classes = common.split_by_class(top_features_df, [0, 1, 4], \"label\", 100)\n",
    "new_num_features = common.reformat_df_by_class(number_classes.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "99ce50ec-7f9c-4785-8838-10ea3e86e2c7",
   "metadata": {
    "id": "99ce50ec-7f9c-4785-8838-10ea3e86e2c7"
   },
   "outputs": [],
   "source": [
    "# split data and labels\n",
    "new_labels, new_features = common.split_labels(new_num_features, \"label\")\n",
    "new_features = np.array(new_features)\n",
    "\n",
    "# get values for expectation maximization algorithm\n",
    "k, x, m, std, prob = EM.prepare_data_EM(new_features, 3, np.array([0.5377, 1.8339, -2.2588]))\n",
    "\n",
    "# set the convergence threshold\n",
    "convergence_threshold = std[1] * 1.0e-6;\n",
    "\n",
    "# Call expecation maximization algorithm\n",
    "new_prob, new_m, new_std, prob_ikn, iterations = EM.simple_expectation_maximization(x.T, k, prob, m, std, convergence_threshold) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548620f2-3cfc-4a4b-99fe-83f3d80b45a9",
   "metadata": {
    "id": "548620f2-3cfc-4a4b-99fe-83f3d80b45a9"
   },
   "source": [
    "#### (a) (5 points) Create 3 clusters for the numerical values that have the best separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "53ee944a-e96f-4508-b783-0ffecfa34594",
   "metadata": {
    "id": "53ee944a-e96f-4508-b783-0ffecfa34594"
   },
   "outputs": [],
   "source": [
    "# get clusters from EM\n",
    "clusters = EM.get_clusters(prob_ikn, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d9dca-4cb0-4dc3-b24d-7881737d0b98",
   "metadata": {
    "id": "cb5d9dca-4cb0-4dc3-b24d-7881737d0b98"
   },
   "source": [
    "#### (b) (5 points) Display the 3 numerical values using different colors for a good visual representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8292bc34-e24f-458f-a90d-3d5afb16adaa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "id": "8292bc34-e24f-458f-a90d-3d5afb16adaa",
    "outputId": "b5a015e4-be72-4f86-970c-b7b193fdfc3d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot clusters\n",
    "common.plot_clusters(new_num_features, clusters, ['xb', '^r', 'og'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3b1e0714-de20-42f1-93f9-ca0afc5781c2",
   "metadata": {
    "id": "3b1e0714-de20-42f1-93f9-ca0afc5781c2"
   },
   "outputs": [],
   "source": [
    "# Perform another analysis using  features 2 and 20 as suggested in office hours\n",
    "# Get the top two features from the dataframe\n",
    "top_features_df = generated_num_features.filter([\"label\"] + [2, 20], axis=1)\n",
    "\n",
    "# Get 100 class examples of classes [0, 1, 4]\n",
    "number_classes = common.split_by_class(top_features_df, [0, 1, 4], \"label\", 100)\n",
    "new_num_features = common.reformat_df_by_class(number_classes.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b2f114be-660c-42e1-8dbc-972a8f1aac26",
   "metadata": {
    "id": "b2f114be-660c-42e1-8dbc-972a8f1aac26"
   },
   "outputs": [],
   "source": [
    "# set values for expectation maximization algorithm\n",
    "k = 3\n",
    "\n",
    "# split data and labels\n",
    "new_labels, new_features = common.split_labels(new_num_features, \"label\")\n",
    "new_features = np.array(new_features)\n",
    "\n",
    "# get values for expectation maximization algorithm\n",
    "k, x, m, std, prop = EM.prepare_data_EM(new_features, 3, np.array([0.5377, 1.8339, -2.2588]))\n",
    "\n",
    "# set the convergence threshold\n",
    "convergence_threshold = std[1] * 1.0e-6;\n",
    "\n",
    "# Call expecation maximization algorithm\n",
    "new_prob, new_m, new_std, prob_ikn, iterations = EM.simple_expectation_maximization(x.T, k, prob, m, std, convergence_threshold)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ed19c1e6-a2af-491c-915a-371e5836d2a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "ed19c1e6-a2af-491c-915a-371e5836d2a3",
    "outputId": "4941f702-3cef-43af-c248-57cde010a16b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get clusters from EM\n",
    "clusters = EM.get_clusters(prob_ikn, 3)\n",
    "\n",
    "# Plot clusters\n",
    "common.plot_clusters(new_num_features, clusters, ['xb', '^r', 'og'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a038654-04f1-40b5-b3e0-867c87fa2328",
   "metadata": {
    "id": "8a038654-04f1-40b5-b3e0-867c87fa2328"
   },
   "source": [
    "#### (c) (5 points) Provide an analysis of your results, e.g., what is your observation of the results, how well did the clusters group each class, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcb9743-7026-488b-81ff-25d0d7c29f84",
   "metadata": {
    "id": "6dcb9743-7026-488b-81ff-25d0d7c29f84"
   },
   "source": [
    "The first analysis used FDR feature ranking to determine the best features to separate classes 0, 1, and 4. The second analysis used features 2 and 20 as suggested during office hours. Both implementations generated three distinct clusters for the numerical classes. The expectation-maximization algorithm generated these clusters by calculating the membership probability of each example based on posterior probabilities. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673630ee-d8f9-4200-973a-7203a0abad33",
   "metadata": {
    "id": "673630ee-d8f9-4200-973a-7203a0abad33"
   },
   "source": [
    "## Problem 2 - Machine Learning\n",
    "45 Points Total\n",
    "\n",
    "In this problem the features generated from HW2 for the numerical data set are to be used. This is the starting point for this problem. A minimum of 5,000 observations need to be used in the problem. A data set developed with the numericalFeatureGeneratorExample.m will also be provided if needed. The updated data is provided as an Excel file with 42,000 observations and 60 features, 20 from each direction. In this assignment data processing and machine learning techniques need to be combined. The best combination is determined by the best classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5992ce4c-9e36-4204-8da4-1b2e590d6a70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "5992ce4c-9e36-4204-8da4-1b2e590d6a70",
    "outputId": "480adfdb-6d29-42ce-c50a-28ebb25de349"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>538.267964</td>\n",
       "      <td>-314.023125</td>\n",
       "      <td>443.809967</td>\n",
       "      <td>470.780028</td>\n",
       "      <td>176.561668</td>\n",
       "      <td>-336.130920</td>\n",
       "      <td>23.221391</td>\n",
       "      <td>-45.523748</td>\n",
       "      <td>-232.436917</td>\n",
       "      <td>...</td>\n",
       "      <td>-90.463868</td>\n",
       "      <td>107.934027</td>\n",
       "      <td>25.417533</td>\n",
       "      <td>-97.235438</td>\n",
       "      <td>-66.589588</td>\n",
       "      <td>22.468479</td>\n",
       "      <td>-111.476083</td>\n",
       "      <td>62.807185</td>\n",
       "      <td>74.771969</td>\n",
       "      <td>-7.480156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-238.730010</td>\n",
       "      <td>224.609513</td>\n",
       "      <td>-197.464121</td>\n",
       "      <td>23.557813</td>\n",
       "      <td>-219.122649</td>\n",
       "      <td>-223.695514</td>\n",
       "      <td>-172.689736</td>\n",
       "      <td>125.561839</td>\n",
       "      <td>-194.150108</td>\n",
       "      <td>...</td>\n",
       "      <td>44.464226</td>\n",
       "      <td>-7.825244</td>\n",
       "      <td>-5.260700</td>\n",
       "      <td>18.905444</td>\n",
       "      <td>9.593545</td>\n",
       "      <td>-40.015688</td>\n",
       "      <td>-96.469679</td>\n",
       "      <td>24.317962</td>\n",
       "      <td>-137.943930</td>\n",
       "      <td>94.025390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>51.647165</td>\n",
       "      <td>-27.271305</td>\n",
       "      <td>-185.258708</td>\n",
       "      <td>-50.103687</td>\n",
       "      <td>216.830344</td>\n",
       "      <td>-207.152351</td>\n",
       "      <td>60.301310</td>\n",
       "      <td>95.431402</td>\n",
       "      <td>-117.051561</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.722596</td>\n",
       "      <td>-3.039582</td>\n",
       "      <td>-26.963181</td>\n",
       "      <td>-18.563280</td>\n",
       "      <td>16.095458</td>\n",
       "      <td>-81.075489</td>\n",
       "      <td>-42.589100</td>\n",
       "      <td>52.083444</td>\n",
       "      <td>-29.080312</td>\n",
       "      <td>42.344233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>110.890600</td>\n",
       "      <td>62.854265</td>\n",
       "      <td>-97.528878</td>\n",
       "      <td>-21.291295</td>\n",
       "      <td>297.976619</td>\n",
       "      <td>-32.899732</td>\n",
       "      <td>34.647964</td>\n",
       "      <td>-85.574818</td>\n",
       "      <td>-60.120835</td>\n",
       "      <td>...</td>\n",
       "      <td>23.112458</td>\n",
       "      <td>-62.558569</td>\n",
       "      <td>-115.846264</td>\n",
       "      <td>-16.405413</td>\n",
       "      <td>-37.548852</td>\n",
       "      <td>-269.649782</td>\n",
       "      <td>-130.725868</td>\n",
       "      <td>-23.526366</td>\n",
       "      <td>-20.448849</td>\n",
       "      <td>37.234782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-300.296735</td>\n",
       "      <td>152.547221</td>\n",
       "      <td>-91.949199</td>\n",
       "      <td>90.416744</td>\n",
       "      <td>-453.385929</td>\n",
       "      <td>-89.195463</td>\n",
       "      <td>-15.051828</td>\n",
       "      <td>-38.036779</td>\n",
       "      <td>-190.363654</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.107534</td>\n",
       "      <td>30.400739</td>\n",
       "      <td>-47.075128</td>\n",
       "      <td>-13.092383</td>\n",
       "      <td>-85.371052</td>\n",
       "      <td>-141.450375</td>\n",
       "      <td>-36.200100</td>\n",
       "      <td>114.188444</td>\n",
       "      <td>-21.988893</td>\n",
       "      <td>-46.480710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label           0           1           2           3           4   \n",
       "0      1  538.267964 -314.023125  443.809967  470.780028  176.561668  \\\n",
       "1      0 -238.730010  224.609513 -197.464121   23.557813 -219.122649   \n",
       "2      1   51.647165  -27.271305 -185.258708  -50.103687  216.830344   \n",
       "3      4  110.890600   62.854265  -97.528878  -21.291295  297.976619   \n",
       "4      0 -300.296735  152.547221  -91.949199   90.416744 -453.385929   \n",
       "\n",
       "            5           6           7           8  ...         50          51   \n",
       "0 -336.130920   23.221391  -45.523748 -232.436917  ... -90.463868  107.934027  \\\n",
       "1 -223.695514 -172.689736  125.561839 -194.150108  ...  44.464226   -7.825244   \n",
       "2 -207.152351   60.301310   95.431402 -117.051561  ... -12.722596   -3.039582   \n",
       "3  -32.899732   34.647964  -85.574818  -60.120835  ...  23.112458  -62.558569   \n",
       "4  -89.195463  -15.051828  -38.036779 -190.363654  ... -28.107534   30.400739   \n",
       "\n",
       "           52         53         54          55          56          57   \n",
       "0   25.417533 -97.235438 -66.589588   22.468479 -111.476083   62.807185  \\\n",
       "1   -5.260700  18.905444   9.593545  -40.015688  -96.469679   24.317962   \n",
       "2  -26.963181 -18.563280  16.095458  -81.075489  -42.589100   52.083444   \n",
       "3 -115.846264 -16.405413 -37.548852 -269.649782 -130.725868  -23.526366   \n",
       "4  -47.075128 -13.092383 -85.371052 -141.450375  -36.200100  114.188444   \n",
       "\n",
       "           58         59  \n",
       "0   74.771969  -7.480156  \n",
       "1 -137.943930  94.025390  \n",
       "2  -29.080312  42.344233  \n",
       "3  -20.448849  37.234782  \n",
       "4  -21.988893 -46.480710  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the data\n",
    "generated_num_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9b85bfc3-ede0-4349-a4fa-8556869ff398",
   "metadata": {
    "id": "9b85bfc3-ede0-4349-a4fa-8556869ff398"
   },
   "outputs": [],
   "source": [
    "# Separate labels and features\n",
    "num_features_labels, num_features = common.split_labels(generated_num_features.iloc[:5000, :], \"label\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa636cd-7f2f-440c-8cfe-3e3ab910a421",
   "metadata": {
    "id": "3aa636cd-7f2f-440c-8cfe-3e3ab910a421"
   },
   "source": [
    "### 1. [5 points] Use a minimum of one of following data preprocessing methods (If more than one method, the processing order is up to you. Built-ins are allowed.):\n",
    "\n",
    "(a) Data Normalization\n",
    "\n",
    "(b) Outlier Removal\n",
    "\n",
    "(c) Feature Ranking and Selection\n",
    "\n",
    "(d) Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bd3911f7-04a0-4456-9666-b04f0e817b6c",
   "metadata": {
    "id": "bd3911f7-04a0-4456-9666-b04f0e817b6c"
   },
   "outputs": [],
   "source": [
    "norm_num_features = norm.normalize(num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c373ce-af82-426f-87c7-954db10db57d",
   "metadata": {
    "id": "d3c373ce-af82-426f-87c7-954db10db57d"
   },
   "source": [
    "### 2. [30 points total] Use the following Machine Learning (ML) techniques (built-ins are allowed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "22b257d3-ed1b-4fbd-b4fa-1e7ea2d8d859",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22b257d3-ed1b-4fbd-b4fa-1e7ea2d8d859",
    "outputId": "d1b2e991-0b78-48ca-ab73-554e63b2a7ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4000 training examples and 1000 testing examples.\n"
     ]
    }
   ],
   "source": [
    "# split data for testing \n",
    "train_data, test_data, train_labels, test_labels = common.split_train_test(norm_num_features, num_features_labels, 0.20)\n",
    "print(f\"There are {len(train_labels)} training examples and {len(test_labels)} testing examples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8666e78-805e-43e6-a1eb-d8df4e6406f2",
   "metadata": {
    "id": "f8666e78-805e-43e6-a1eb-d8df4e6406f2"
   },
   "source": [
    "#### (a) [10 points] Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c561fd8f-3885-4647-b608-ff4639988660",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c561fd8f-3885-4647-b608-ff4639988660",
    "outputId": "42a533d1-7b97-4130-90eb-962ab2c7fcd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bayes classifier had an accuracy of 94.7% on the test data.\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0    1    2    3   4   5    6   7   8   9\n",
      "Actual                                               \n",
      "0          92    0    0    0   0   1    0   0   1   0\n",
      "1           0  101    3    0   0   0    0   0   8   0\n",
      "2           1    0  112    0   0   0    0   0   2   0\n",
      "3           0    0    1  106   0   0    0   0   3   0\n",
      "4           0    0    1    0  87   0    0   0   0   0\n",
      "5           0    0    0    5   0  85    0   0   0   0\n",
      "6           1    0    0    0   0   1  101   0   0   0\n",
      "7           0    0    3    0   2   0    0  87   1   4\n",
      "8           1    0    1    2   0   0    0   0  90   0\n",
      "9           0    0    1    0   6   0    0   3   1  86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the model with the training dataset\n",
    "train_set = pd.concat([train_labels, train_data], axis=1)\n",
    "model = bayes_model.build_model(train_set, [i for i in range(10)], \"label\")\n",
    "\n",
    "# Determine classification accuracy with the test dataset\n",
    "classifications, y_posterior = bayes.bayes_classifier(test_data, model)\n",
    "labels = list(test_labels)\n",
    "accuracy = common.get_accuracy(classifications, labels)\n",
    "print(f\"The Bayes classifier had an accuracy of {accuracy}% on the test data.\")\n",
    "common.confusion_matrix(labels, classifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a149e-4a10-40d7-a4f4-b2e1023a83e7",
   "metadata": {
    "id": "b50a149e-4a10-40d7-a4f4-b2e1023a83e7"
   },
   "source": [
    "#### (b) [10 points] Parzen Window (Gaussian kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c39ad1db-5483-40fd-a954-a6eef3faee69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c39ad1db-5483-40fd-a954-a6eef3faee69",
    "outputId": "3ed24575-e467-4e12-b0fb-f0184dea2c49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Parzen window algorithm with training and test set\n",
      "Parzen window training...\n",
      "\n",
      "Training with class 0/9\n",
      "Training with class 1/9\n",
      "Training with class 2/9\n",
      "Training with class 3/9\n",
      "Training with class 4/9\n",
      "Training with class 5/9\n",
      "Training with class 6/9\n",
      "Training with class 7/9\n",
      "Training with class 8/9\n",
      "Training with class 9/9\n",
      "\n",
      "Accuracy: 91.7%\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0    1    2    3   4   5    6   7   8   9\n",
      "Actual                                               \n",
      "0          89    1    0    1   0   1    2   0   0   0\n",
      "1           0  110    1    0   0   0    0   1   0   0\n",
      "2           1    2  107    0   0   0    0   2   1   2\n",
      "3           1    0    0  100   0   4    0   1   3   1\n",
      "4           0    1    0    0  82   0    0   1   0   4\n",
      "5           0    1    0    4   0  79    2   0   0   4\n",
      "6           1    0    0    0   0   1  101   0   0   0\n",
      "7           0    4    0    0   2   0    0  86   0   5\n",
      "8           2    1    1    2   1   6    0   2  79   0\n",
      "9           0    2    1    0   4   0    0   5   1  84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classes = [i for i in range(10)]\n",
    "print(\"Testing Parzen window algorithm with training and test set\")\n",
    "parzens = parzen.run_parzen_window(train_data, train_labels, test_data, test_labels, classes, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e018f0-7407-498b-99bb-9fdc38a38a75",
   "metadata": {
    "id": "e4e018f0-7407-498b-99bb-9fdc38a38a75"
   },
   "source": [
    "#### (c) [10 points] Neural Network, method of your choice from a built-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "50c0004e-597d-414b-b4de-45b61ef277b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50c0004e-597d-414b-b4de-45b61ef277b9",
    "outputId": "1014579e-eb88-4b08-cd24-f3e916431a1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "400/400 [==============================] - 0s 638us/step - loss: 1.3031 - accuracy: 0.5790\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 0s 650us/step - loss: 0.6190 - accuracy: 0.8005\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 0s 651us/step - loss: 0.4926 - accuracy: 0.8505\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 0s 643us/step - loss: 0.4550 - accuracy: 0.8575\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 0s 647us/step - loss: 0.3945 - accuracy: 0.8742\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 0s 650us/step - loss: 0.3675 - accuracy: 0.8838\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 0s 642us/step - loss: 0.3307 - accuracy: 0.8907\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 0s 656us/step - loss: 0.3058 - accuracy: 0.9022\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 0s 646us/step - loss: 0.2796 - accuracy: 0.9120\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 0s 646us/step - loss: 0.2842 - accuracy: 0.9060\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 0s 643us/step - loss: 0.2569 - accuracy: 0.9202\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 0s 647us/step - loss: 0.2298 - accuracy: 0.9243\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 0s 638us/step - loss: 0.2405 - accuracy: 0.9230\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 0s 651us/step - loss: 0.2276 - accuracy: 0.9247\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 0s 641us/step - loss: 0.2034 - accuracy: 0.9360\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 0s 638us/step - loss: 0.1987 - accuracy: 0.9315\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 0s 650us/step - loss: 0.1796 - accuracy: 0.9400\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 0s 641us/step - loss: 0.1634 - accuracy: 0.9463\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 0s 641us/step - loss: 0.1549 - accuracy: 0.9460\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 0s 651us/step - loss: 0.1444 - accuracy: 0.9520\n",
      "100/100 [==============================] - 0s 368us/step\n",
      "The Accuracy against the test data was: 92.4\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0    1   2    3   4   5    6   7   8   9\n",
      "Actual                                              \n",
      "0          88    0   1    2   0   0    2   0   1   0\n",
      "1           0  107   1    2   0   1    0   0   0   1\n",
      "2           1    1  99    6   2   0    1   3   2   0\n",
      "3           0    0   0  108   0   0    0   0   2   0\n",
      "4           0    0   0    0  85   0    0   0   0   3\n",
      "5           1    0   1    8   1  71    2   0   3   3\n",
      "6           0    0   1    0   1   1  100   0   0   0\n",
      "7           0    1   0    0   3   0    0  88   0   5\n",
      "8           0    0   1    1   0   0    0   1  91   0\n",
      "9           0    1   0    1   5   0    0   1   2  87\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "labels=keras.utils.to_categorical(train_labels,10)\n",
    "\n",
    "def multilayer_perceptron(train_data, test_data, train_labels, test_labels, hidden_layers: list, output_activation: str, loss_function: str, show_epochs:bool):\n",
    "    \"\"\"\n",
    "    Create a neural network and evaluate (multiclass only)\n",
    "    Inputs: data: a normalized dataset\n",
    "    hidden_layers: an array representing the hidden layers of the neural network. \n",
    "                  ex. hidden_layers = [[128, 'relu'], [256, 'relu']] is two hidden\n",
    "                  layers, one with 128 nodes and one with 256 nodes. Both layers use\n",
    "                  the relu activation function\n",
    "    output_activation: The type of activation function in the output layer\n",
    "\n",
    "    \"\"\"\n",
    "    num_classes = len(set(train_labels))\n",
    "    new_train_labels=keras.utils.to_categorical(train_labels,num_classes)\n",
    "  \n",
    "    # Feed forward neural network\n",
    "    model = Sequential()\n",
    "\n",
    "    # Hidden layers \n",
    "    for i, layer in enumerate(hidden_layers):\n",
    "        model.add(Dense(layer[0], layer[1], input_dim=60))\n",
    "    #Output Layer\n",
    "    model.add(Dense(10, activation=output_activation))\n",
    "\n",
    "    #Compiling the neural network\n",
    "    model.compile(optimizer ='adam',loss=loss_function, metrics =['accuracy'])\n",
    "\n",
    "    if show_epochs:\n",
    "      history = model.fit(train_data,new_train_labels, batch_size=10, epochs=20)\n",
    "    else:\n",
    "      history = model.fit(train_data,new_train_labels, batch_size=10, epochs=20, verbose=0)\n",
    "\n",
    "    # Get predictions to calculate accuracy and confusion matrix\n",
    "    predictions = model.predict(test_data, batch_size=10)\n",
    "    predictions = predictions.argmax(axis=1)\n",
    "    \n",
    "    # print accuracy and confusion matrix\n",
    "    accuracy = common.get_accuracy(list(test_labels), predictions)\n",
    "    print(f\"The Accuracy against the test data was: {accuracy}\")\n",
    "    common.confusion_matrix(list(test_labels), predictions)\n",
    "\n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "Accuracy = multilayer_perceptron(train_data, test_data, train_labels, test_labels, [[128, 'relu'], [128, 'relu'],[256, 'relu']], 'softmax', 'categorical_crossentropy', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f7517-e264-4d82-97f3-314536da4a8d",
   "metadata": {
    "id": "292f7517-e264-4d82-97f3-314536da4a8d"
   },
   "source": [
    "### 3. [5 points] Use 5-fold cross validation (from HW 3) on selected process from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2f49fabb-e4ed-4d8e-bd2e-046156ffd70f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503
    },
    "id": "2f49fabb-e4ed-4d8e-bd2e-046156ffd70f",
    "outputId": "98167515-f874-41d8-e7a6-1d7f83774596"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold validation with the Bayes classifier\n",
      "\n",
      "Experiment 1:\n",
      "\n",
      "The Bayes classifier had an accuracy of 95.9% on the test data.\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0    1    2   3   4   5   6   7   8    9\n",
      "Actual                                              \n",
      "0          77    0    0   0   0   0   0   0   1    0\n",
      "1           0  117    0   0   0   0   0   0   1    0\n",
      "2           0    0  103   0   0   0   0   0   2    0\n",
      "3           0    0    0  93   0   0   0   0   1    1\n",
      "4           0    0    2   0  95   0   0   0   0    0\n",
      "5           0    0    0   2   0  88   0   1   2    1\n",
      "6           1    0    0   0   0   0  97   0   0    0\n",
      "7           1    0    2   0   1   1   0  94   2    2\n",
      "8           0    0    0   5   0   1   0   0  92    0\n",
      "9           1    0    0   0   7   0   0   2   1  103\n",
      "\n",
      "Experiment 2:\n",
      "\n",
      "The Bayes classifier had an accuracy of 95.6% on the test data.\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0    1    2   3    4   5   6   7   8   9\n",
      "Actual                                              \n",
      "0          97    0    1   0    0   0   0   0   2   1\n",
      "1           0  110    3   0    0   0   0   0   6   1\n",
      "2           0    0  109   0    1   0   0   0   1   0\n",
      "3           0    0    5  96    0   0   0   0   2   1\n",
      "4           0    0    0   0  107   0   1   0   1   0\n",
      "5           0    0    0   0    0  87   0   0   1   0\n",
      "6           0    0    0   0    1   2  86   0   1   0\n",
      "7           0    0    4   0    0   0   0  88   1   0\n",
      "8           0    0    1   2    0   0   0   0  86   0\n",
      "9           0    0    0   1    2   1   0   1   0  90\n",
      "\n",
      "Experiment 3:\n",
      "\n",
      "The Bayes classifier had an accuracy of 93.0% on the test data.\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0    1    2   3   4   5   6    7   8   9\n",
      "Actual                                              \n",
      "0          93    0    1   0   0   0   0    0   0   0\n",
      "1           0  106    1   0   0   0   0    0   7   0\n",
      "2           0    0  107   1   1   0   0    0   0   0\n",
      "3           0    0    1  87   0   2   0    0   4   0\n",
      "4           0    0    0   0  89   0   0    0   0   0\n",
      "5           0    0    2   5   0  81   0    0   3   0\n",
      "6           1    0    0   0   0   2  92    0   4   0\n",
      "7           0    0    6   1   4   0   0  103   0  10\n",
      "8           2    0    3   2   0   0   0    0  91   1\n",
      "9           1    0    1   2   1   0   0    0   1  81\n",
      "\n",
      "Experiment 4:\n",
      "\n",
      "The Bayes classifier had an accuracy of 96.1% on the test data.\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted    0   1    2   3   4    5    6   7    8   9\n",
      "Actual                                                \n",
      "0          105   0    1   0   0    2    0   0    1   0\n",
      "1            0  96    3   0   0    0    0   1    1   0\n",
      "2            0   0  110   0   0    0    0   0    1   0\n",
      "3            0   0    3  86   0    0    0   0    0   0\n",
      "4            0   0    0   0  89    0    0   0    0   1\n",
      "5            0   0    0   3   0  104    0   0    0   0\n",
      "6            0   0    0   0   1    0  109   0    0   0\n",
      "7            0   0    1   0   0    0    0  92    1   4\n",
      "8            0   0    2   0   0    1    0   0  101   0\n",
      "9            0   0    0   2   3    0    0   5    2  69\n",
      "\n",
      "Experiment 5:\n",
      "\n",
      "The Bayes classifier had an accuracy of 94.7% on the test data.\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted    0   1    2   3   4   5    6   7   8   9\n",
      "Actual                                              \n",
      "0          112   0    0   0   0   0    0   0   0   0\n",
      "1            0  96    3   0   0   0    0   0   6   0\n",
      "2            1   0  104   0   0   0    0   1   3   0\n",
      "3            0   0    3  94   0   1    0   0   0   0\n",
      "4            1   0    1   0  89   0    0   0   1   0\n",
      "5            0   0    1   1   0  82    0   0   4   1\n",
      "6            0   0    0   0   1   1  117   0   0   0\n",
      "7            0   0    2   0   0   0    0  80   2   4\n",
      "8            1   0    0   2   0   1    0   0  83   0\n",
      "9            0   0    2   2   2   0    0   4   1  90\n",
      "\n",
      "The average accuracy among the experiments was 95.06%\n"
     ]
    }
   ],
   "source": [
    "norm_numbers_data = pd.concat([num_features_labels, norm_num_features], axis=1)\n",
    "print(\"5-fold validation with the Bayes classifier\\n\")\n",
    "bayes.bayes_classifier_k_fold(norm_numbers_data, 5, [i for i in range(10)], \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "704d5038-da22-4822-8322-0d1cd644cb4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "704d5038-da22-4822-8322-0d1cd644cb4e",
    "outputId": "f5cf2d4f-92dc-4c01-c7c0-e90e0983eea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold validation with parzen window approach\n",
      "\n",
      "Experiment 1 accuracy: 91.4%\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0    1    2   3   4   5   6   7   8   9\n",
      "Actual                                             \n",
      "0          96    0    0   0   0   1   0   0   0   0\n",
      "1           0  119    1   0   1   1   0   0   0   1\n",
      "2           1    4  103   3   0   0   0   4   1   1\n",
      "3           2    1    2  76   0   2   0   2   0   0\n",
      "4           0    2    0   0  86   0   0   1   0   5\n",
      "5           0    1    0   1   1  84   0   1   1   0\n",
      "6           0    0    0   0   0   0  90   0   0   0\n",
      "7           0    3    0   0   1   1   0  94   1   3\n",
      "8           1    3    1   9   1   3   1   0  82   1\n",
      "9           0    1    0   0   6   0   0   9   0  84\n",
      "\n",
      "Experiment 2 accuracy: 92.1%\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted    0    1    2   3   4   5   6   7   8   9\n",
      "Actual                                              \n",
      "0          101    0    0   0   0   1   0   0   0   0\n",
      "1            0  118    1   0   0   0   0   1   0   0\n",
      "2            0    4  107   0   0   1   0   6   4   0\n",
      "3            0    0    3  77   0   1   0   0   3   2\n",
      "4            0    1    0   0  80   0   0   2   0   9\n",
      "5            0    1    0   1   1  87   2   0   0   2\n",
      "6            0    0    0   0   0   1  93   0   0   0\n",
      "7            0    0    0   0   1   0   0  95   0   3\n",
      "8            0    4    4   8   0   4   0   0  87   2\n",
      "9            0    0    0   0   3   0   1   2   0  76\n",
      "\n",
      "Experiment 3 accuracy: 92.9%\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted    0    1    2   3   4   5    6    7   8   9\n",
      "Actual                                                \n",
      "0          104    0    0   1   0   2    1    0   1   0\n",
      "1            0  110    0   0   0   0    0    0   0   0\n",
      "2            1    0  104   0   1   0    0    1   0   1\n",
      "3            0    1    0  98   0   3    0    0   0   2\n",
      "4            0    2    0   0  81   0    2    0   0   8\n",
      "5            0    0    1   2   0  81    2    0   0   1\n",
      "6            0    0    0   0   0   0  102    0   0   0\n",
      "7            0    2    1   1   1   1    0  105   0   0\n",
      "8            1    1    2   4   0   1    1    0  64   5\n",
      "9            1    0    1   0   8   0    0    7   0  80\n",
      "\n",
      "Experiment 4 accuracy: 91.5%\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0    1   2   3   4   5    6   7   8   9\n",
      "Actual                                             \n",
      "0          80    0   0   1   0   1    1   0   0   1\n",
      "1           0  113   0   0   0   0    0   1   1   0\n",
      "2           1    3  90   1   1   0    0   0   2   1\n",
      "3           1    0   2  97   0   0    0   1   1   1\n",
      "4           0    0   0   0  83   0    0   2   0  13\n",
      "5           2    0   0   6   0  82    3   1   1   1\n",
      "6           3    0   0   0   0   0  109   0   0   0\n",
      "7           0    4   3   0   1   0    0  93   0   1\n",
      "8           1    0   0   5   0   4    1   1  82   1\n",
      "9           2    1   0   0   4   0    0   3   0  86\n",
      "\n",
      "Experiment 5 accuracy: 92.5%\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0   1   2   3   4   5    6   7   8   9\n",
      "Actual                                            \n",
      "0          97   0   0   1   0   0    4   0   0   0\n",
      "1           0  89   0   0   0   0    0   1   0   0\n",
      "2           1   2  91   1   0   0    0   4   0   0\n",
      "3           0   0   1  96   0   3    0   0   2   0\n",
      "4           0   0   1   0  93   1    1   0   0   4\n",
      "5           0   0   0   0   0  98    0   0   1   4\n",
      "6           1   0   0   0   0   2  114   0   0   1\n",
      "7           0   2   0   0   2   0    0  85   0   2\n",
      "8           0   3   2   5   2   4    0   2  73   1\n",
      "9           1   0   0   3   5   0    0   5   0  89\n",
      "\n",
      "The average accuracy among the experiments was 92.08%\n"
     ]
    }
   ],
   "source": [
    "norm_numbers_data = pd.concat([num_features_labels, norm_num_features], axis=1)\n",
    "print(\"5-fold validation with parzen window approach\\n\")\n",
    "parzens = parzen.parzen_window_k_fold(norm_numbers_data, 5, [i for i in range(10)], \"label\", 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "PjcP1GttNknC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PjcP1GttNknC",
    "outputId": "21a40ada-b5ca-4ec9-8f8a-e85b905a136f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold validation with the feed forward neural network approach\n",
      "\n",
      "Experiment 1:\n",
      "100/100 [==============================] - 0s 343us/step\n",
      "The Accuracy against the test data was: 90.1\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0    1   2   3   4   5    6   7   8   9\n",
      "Actual                                             \n",
      "0          96    0   0   0   0   0    3   0   2   0\n",
      "1           0  114   2   0   0   0    1   1   0   0\n",
      "2           1    4  93   0   0   0    7   4   5   0\n",
      "3           0    0   2  85   0   5    0   2   3   0\n",
      "4           2    1   0   0  94   1    3   3   0   0\n",
      "5           2    0   0   0   0  73    2   0   0   1\n",
      "6           0    0   0   0   0   0  107   0   1   0\n",
      "7           1    2   2   0   0   0    0  92   0   1\n",
      "8           1    6   0   1   0   1    3   0  74   0\n",
      "9           4    3   0   0  13   1    1   1   0  73\n",
      "\n",
      "Experiment 2:\n",
      "100/100 [==============================] - 0s 352us/step\n",
      "The Accuracy against the test data was: 92.1\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0    1   2   3   4   5   6    7   8   9\n",
      "Actual                                             \n",
      "0          93    0   0   2   0   0   1    0   0   0\n",
      "1           0  122   0   0   0   0   0    0   2   0\n",
      "2           0    0  88   3   0   0   0    0   2   1\n",
      "3           0    1   2  93   0   0   0    1   1   2\n",
      "4           1    0   0   0  83   0   1    0   0   9\n",
      "5           3    0   2   5   1  88   1    0   2   4\n",
      "6           1    0   1   0   1   1  92    0   0   0\n",
      "7           0    2   1   0   1   0   0  102   1   6\n",
      "8           0    2   1   4   0   0   0    0  74   2\n",
      "9           1    1   0   2   1   0   0    1   2  86\n",
      "\n",
      "Experiment 3:\n",
      "100/100 [==============================] - 0s 352us/step\n",
      "The Accuracy against the test data was: 89.5\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0   1    2   3   4   5    6   7   8   9\n",
      "Actual                                             \n",
      "0          98   0    0   0   0   0    1   0   0   1\n",
      "1           0  95    3   0   0   0    0   1   0   0\n",
      "2           1   1  101   0   0   0    3   2   2   0\n",
      "3           2   4    6  93   0   1    1   0   4   0\n",
      "4           0   0    0   0  85   0    7   0   0   0\n",
      "5           1   6    3   7   0  66    6   1   2   1\n",
      "6           1   0    0   0   0   0  101   0   0   0\n",
      "7           2   1    3   0   0   0    1  91   1   0\n",
      "8           0   1    1   0   0   1    6   0  87   0\n",
      "9           0   1    0   2   8   0    0   5   4  78\n",
      "\n",
      "Experiment 4:\n",
      "100/100 [==============================] - 0s 339us/step\n",
      "The Accuracy against the test data was: 91.5\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted    0    1    2   3   4   5   6   7    8   9\n",
      "Actual                                               \n",
      "0          106    0    0   0   0   1   2   0    0   1\n",
      "1            0  109    0   0   0   1   1   0    0   0\n",
      "2            1    2  107   0   2   0   0   1    1   1\n",
      "3            1    0    2  58   0   7   0   0    2   0\n",
      "4            0    0    2   0  75   0   2   0    1   8\n",
      "5            0    1    2   3   0  91   0   0    4   1\n",
      "6            4    0    1   0   1   3  92   0    1   0\n",
      "7            1    0    0   1   0   1   0  92    0   2\n",
      "8            1    2    0   6   0   2   0   0  103   4\n",
      "9            1    0    1   0   0   3   0   0    0  82\n",
      "\n",
      "Experiment 5:\n",
      "100/100 [==============================] - 0s 327us/step\n",
      "The Accuracy against the test data was: 90.5\n",
      "Confusion Matrix:\n",
      "\n",
      "Predicted   0    1    2   3   4   5    6   7   8   9\n",
      "Actual                                              \n",
      "0          86    0    0   0   0   0    1   0   0   0\n",
      "1           0  105    0   0   0   1    0   0   0   0\n",
      "2           0    3  103   0   2   0    2   2   0   0\n",
      "3           0    0    0  82   0   5    1   0  14   0\n",
      "4           1    0    0   0  90   0    2   0   1   5\n",
      "5           3    0    0   0   0  75    6   0   6   0\n",
      "6           3    0    0   0   1   1  103   0   0   0\n",
      "7           0    0    6   1   1   0    0  87   1   3\n",
      "8           1    2    1   0   0   1    1   0  86   2\n",
      "9           3    1    1   0   3   2    0   3   2  88\n",
      "\n",
      "The average accuracy among the experiments was 90.74%\n"
     ]
    }
   ],
   "source": [
    "# K-fold with feed forward neural network\n",
    "def NN_k_fold(data: object, num_folds: int, label_name: str, hidden_layers: object, output_activation: str, loss_function: str):\n",
    "    \n",
    "    experiments = k_fold.k_fold_validation(data, num_folds)\n",
    "    accuracy_totals = {}\n",
    "    for experiment in experiments:\n",
    "        # get test data and convert labels to number\n",
    "        test_df = experiments[experiment][\"test\"]\n",
    "        test_labels = np.array(test_df[label_name])\n",
    "        data = test_df.drop([label_name], axis=1)\n",
    "        test_data = np.array(data)\n",
    "        # get training data and convert labels to numbers\n",
    "        train_df = experiments[experiment][\"train\"]\n",
    "        train_labels = np.array(train_df[label_name])\n",
    "        data = train_df.drop([label_name], axis=1)\n",
    "        train_data = np.array(data)\n",
    "        \n",
    "        print(f\"Experiment {experiment}:\")\n",
    "        acc = multilayer_perceptron(train_data, test_data, train_labels, test_labels, hidden_layers, output_activation, loss_function, False)\n",
    "        accuracy_totals[experiment] = acc\n",
    "    print(f\"The average accuracy among the experiments was {round(sum(accuracy_totals.values())/len(accuracy_totals), 2)}%\")\n",
    "\n",
    "print(\"5-fold validation with the feed forward neural network approach\\n\")\n",
    "NN_k_fold(norm_numbers_data, 5, \"label\", [[128, 'relu'], [256, 'relu']], 'softmax', 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4004dd60-24f8-442d-b505-a300a5f9dd85",
   "metadata": {
    "id": "4004dd60-24f8-442d-b505-a300a5f9dd85",
    "tags": []
   },
   "source": [
    "### 4. [5 points total] Provide an analysis of your results:\n",
    "\n",
    "#### (a) [2.5 points] What combination from the above methods gave the best results? The best results is considered the highest classification accuracy for the 10 digits from the 5-fold cross validation results.\n",
    "\n",
    "The three algorithms were comparable in performance when paired with normalization. All three algorithms had over 90% classification accuracy. The Bayes Classifier had slightly higher classification accuracy than the other methods when tested with 5-fold cross-validation, reaching an average accuracy of 95.06%. \n",
    "\n",
    "#### (b) [2.5 points] Was there any part of the combination of the techniques used computationally expensive and why?\n",
    "\n",
    "The parzen window approach was computationally expensive due to the calculations in the gaussian kernel function used to estimate a probability density function. The neural network was also computationally expensive because it contained multiple hidden layers. The first hidden layer contained 256 nodes, and the second hidden layer contained 128 nodes. The Bayes Classifier was the most computationally efficient approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d8264b-fe13-4b0f-9fbd-3bacd25d8795",
   "metadata": {
    "id": "c5d8264b-fe13-4b0f-9fbd-3bacd25d8795"
   },
   "source": [
    "## Problem 3 - Game Theory\n",
    "25 Points Total\n",
    "\n",
    "In the tic-tac-toe code provided add the following method to allow an unbeatable AI in your game.Implement either MiniMax or Alpha Beta to play against and allow the player to choose the skill level.\n",
    "\n",
    "1. Best Move (Provided) - Skill Level Easy\n",
    "2. Utility Based Agent (PA1) - Skill Level Medium\n",
    "3. [25 points] Skill Level Hard - Implemented either the MiniMax or Alpha Beta algorithm from the Game Theory document for the tic-tac-toe game. You will need to alter the provided pseudo code to input the game board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1956faa2-5310-4040-a54b-fba22c234d1f",
   "metadata": {
    "id": "1956faa2-5310-4040-a54b-fba22c234d1f"
   },
   "outputs": [],
   "source": [
    "#%run -i \"game_theory/TicTacProject_Incomplete.py\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
